# Chatbots with Context (Memory)

Without context, the model doesn’t retain memory of previous prompts. 
As a result, the model may either misunderstand the user, requiring more context, 
or provide a random response unrelated to the discussion.

Without context, a history variable is created to store the user’s request and the text generated by the model. 
When the user poses a new question, the history is inserted before the new question. So it means, that for each 
api calling will be processed all the history. This implies in a higher cost, as you are charged by token, and, also 
there is a problem related to the maximum number of tokens allowed by the OpenAI API.
Some possible solutions:

- keep in the history only a limited number of past messages

- apply a selective context: create embeddings for all interactions. Check the cosine similarity between the user input
and the past interactions in order to selected the closests ones.


Another considerations that can help to improve the results:

- Choose a more advanced algorithm that carries over the entire contex
- Use a vector database for storing history and performing sorting (Ex. Faiss, Annoy, Milvus, Weaviate, etc)
- Adjusting the number of interactions to carry over based on the user’s prompt and context
- Request more than one response from the API and select the more similar to the context
